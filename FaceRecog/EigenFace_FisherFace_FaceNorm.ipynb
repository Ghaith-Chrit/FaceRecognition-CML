{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of EigenFace and FisherFace + FaceFrontalization\n",
    "\n",
    "Using KNN as the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as urlreq\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "import scipy.io as scio\n",
    "from face_frontalization import frontalize\n",
    "from face_frontalization import camera_calibration as calib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 8\n",
    "\n",
    "min_image_num = 10\n",
    "training_set_size = 10\n",
    "training_image_num = 5\n",
    "num_misclassified_to_show = 5\n",
    "\n",
    "frontalize_face = False\n",
    "crop_face_after_norm = True\n",
    "face_image_target_size = (64, 64)\n",
    "base_folder = \"data/face/lfw-deepfunneled/lfw-deepfunneled\"\n",
    "\n",
    "haarcascade = \"model_checkpoints/haarcascade.xml\"\n",
    "haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "LBFmodel = \"model_checkpoints/lbfmodel.yaml\"\n",
    "LBFmodel_url = \"https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml\"\n",
    "\n",
    "frontalize_model_name = \"model_dlib\"\n",
    "frontalize_model_path = \"model_checkpoints/model3Ddlib.mat\"\n",
    "\n",
    "eye_mask_mat = \"eyemask\"\n",
    "eye_mask_mat_path = \"model_checkpoints/eyemask.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, url in zip([haarcascade, LBFmodel], [haarcascade_url, LBFmodel_url]):\n",
    "    if os.path.exists(filename):\n",
    "        print(\"File exists\")\n",
    "    else:\n",
    "        urlreq.urlretrieve(url, filename)\n",
    "        print(\"File downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for person in os.listdir(base_folder):\n",
    "    person_dir = os.path.join(base_folder, person)\n",
    "    if os.path.isdir(person_dir):\n",
    "        images = []\n",
    "        for img_name in os.listdir(person_dir):\n",
    "            img_path = os.path.join(person_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        if len(images) >= min_image_num:\n",
    "            data[person] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "people_names = list(data.keys())\n",
    "\n",
    "for person, images in data.items():\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    train_images.extend(images[:training_image_num])\n",
    "    test_images.extend(images[training_image_num:])\n",
    "    train_labels = [person] * training_image_num\n",
    "    test_labels = [person] * (len(images) - training_image_num)\n",
    "\n",
    "    random.seed(random_seed)\n",
    "    other_people = random.sample(\n",
    "        [p for p in people_names if p != person],\n",
    "        2 * (training_set_size - training_image_num),\n",
    "    )\n",
    "\n",
    "    for i, other_person in enumerate(other_people):\n",
    "        random.seed(random_seed)\n",
    "        chosen_image = random.sample(data[other_person], 1)[0]\n",
    "        if i % 2 == 0:\n",
    "            train_images.append(chosen_image)\n",
    "            train_labels.append(\"Unknown\")\n",
    "        else:\n",
    "            test_images.append(chosen_image)\n",
    "            test_labels.append(\"Unknown\")\n",
    "\n",
    "    x_train.append(train_images)\n",
    "    x_test.append(test_images)\n",
    "    y_train.append(train_labels)\n",
    "    y_test.append(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier(haarcascade)\n",
    "landmark_detector = cv2.face.createFacemarkLBF()\n",
    "landmark_detector.loadModel(LBFmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_face(img):\n",
    "    model3D = frontalize.ThreeD_Model(frontalize_model_path, frontalize_model_name)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    if len(faces) == 0:\n",
    "        raise RuntimeError(\"No faces detected.\")\n",
    "\n",
    "    main_face = np.array([max(faces, key=lambda rect: rect[2] * rect[3])])\n",
    "    retval, landmarks = landmark_detector.fit(gray, main_face)\n",
    "    if not retval or len(landmarks) == 0:\n",
    "        raise RuntimeError(\"Could not detect landmarks.\")\n",
    "\n",
    "    # OpenCV returns landmarks as a list, where each element is an array of shape (1, 68, 2).\n",
    "    lmarks = landmarks[0][0]\n",
    "    proj_matrix, _, _, _ = calib.estimate_camera(model3D, lmarks)\n",
    "\n",
    "    eyemask = np.asarray(scio.loadmat(eye_mask_mat_path)[eye_mask_mat])\n",
    "    frontal_raw, frontal_sym = frontalize.frontalize(\n",
    "        img, proj_matrix, model3D.ref_U, eyemask\n",
    "    )\n",
    "\n",
    "    return frontal_raw, frontal_sym\n",
    "\n",
    "\n",
    "def obtain_only_face(frontal_view):\n",
    "    faces = face_detector.detectMultiScale(\n",
    "        frontal_view, scaleFactor=1.1, minNeighbors=5\n",
    "    )\n",
    "\n",
    "    main_face = np.array([max(faces, key=lambda rect: rect[2] * rect[3])])\n",
    "    _, landmarks = landmark_detector.fit(frontal_view, main_face)\n",
    "\n",
    "    lmarks = landmarks[0][0]\n",
    "    hull = cv2.convexHull(np.array(lmarks, dtype=np.int32))\n",
    "\n",
    "    min_x = min(lmarks, key=lambda p: p[0])[0]\n",
    "    max_x = max(lmarks, key=lambda p: p[0])[0]\n",
    "    min_y = min(lmarks, key=lambda p: p[1])[1]\n",
    "    max_y = max(lmarks, key=lambda p: p[1])[1]\n",
    "\n",
    "    mask = np.zeros((frontal_view.shape[0], frontal_view.shape[1]), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [hull], 255)\n",
    "\n",
    "    masked_face = frontal_view.copy()\n",
    "    if masked_face.dtype != np.uint8:\n",
    "        masked_face = np.uint8(np.clip(masked_face, 0, 255))\n",
    "\n",
    "    masked_face[mask == 0] = 0\n",
    "    masked_face = masked_face[\n",
    "        int(min_y) - 5 : int(max_y) + 5, int(min_x) - 5 : int(max_x) + 5\n",
    "    ]\n",
    "\n",
    "    masked_face = cv2.cvtColor(masked_face, cv2.COLOR_BGR2GRAY)\n",
    "    resized_face = cv2.resize(masked_face, face_image_target_size)\n",
    "    return resized_face\n",
    "\n",
    "\n",
    "def normalize_list(image_list, useSym):\n",
    "    input = image_list\n",
    "    if frontalize_face:\n",
    "        input = [normalize_face(x)[1 if useSym else 0] for x in image_list]\n",
    "\n",
    "    if crop_face_after_norm:\n",
    "        return [obtain_only_face(x) for x in input]\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    precision = precision_score(\n",
    "        true_labels,\n",
    "        predicted_labels,\n",
    "        average=\"weighted\",\n",
    "        labels=np.unique(true_labels),\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    recall = recall_score(\n",
    "        true_labels,\n",
    "        predicted_labels,\n",
    "        average=\"weighted\",\n",
    "        labels=np.unique(true_labels),\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    return precision, recall, accuracy\n",
    "\n",
    "\n",
    "def track_misclassifications(test_images, true_labels, predicted_labels):\n",
    "    misclassified_images = []\n",
    "    misclassified_true_labels = []\n",
    "    misclassified_pred_labels = []\n",
    "\n",
    "    true_labels = np.array(true_labels)\n",
    "    misclassified_indices = np.where(predicted_labels != true_labels)[0]\n",
    "\n",
    "    for idx in misclassified_indices:\n",
    "        misclassified_images.append(test_images[idx])\n",
    "        misclassified_true_labels.append(true_labels[idx])\n",
    "        misclassified_pred_labels.append(predicted_labels[idx])\n",
    "\n",
    "    return misclassified_images, misclassified_true_labels, misclassified_pred_labels\n",
    "\n",
    "\n",
    "def visualize_misclassifications(\n",
    "    title, misclassified_images, misclassified_true_labels, misclassified_pred_labels\n",
    "):\n",
    "    random.seed(random_seed)\n",
    "    misclassified_indices_sample = random.sample(\n",
    "        range(len(misclassified_images)),\n",
    "        min(num_misclassified_to_show, len(misclassified_images)),\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    for idx, misclassified_idx in enumerate(misclassified_indices_sample):\n",
    "        image = misclassified_images[misclassified_idx]\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        true_label = misclassified_true_labels[misclassified_idx]\n",
    "        predicted_label = misclassified_pred_labels[misclassified_idx]\n",
    "\n",
    "        plt.subplot(1, num_misclassified_to_show, idx + 1)\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    title = f\"{title} ({f'With Face Frontalization and{\" without\" if not crop_face_after_norm else \"\"} Face Croping' if frontalize_face else 'Without Face Frontalization'})\"\n",
    "    plt.suptitle(title, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_metrics(title, all_precision, all_recall, all_accuracy):\n",
    "    average_precision = np.mean(all_precision)\n",
    "    average_recall = np.mean(all_recall)\n",
    "    average_accuracy = np.mean(all_accuracy)\n",
    "\n",
    "    title = f\"{title} ({f'With Face Frontalization and{\" without\" if not crop_face_after_norm else \"\"} Face Croping' if frontalize_face else 'Without Face Frontalization'})\"\n",
    "\n",
    "    print(title)\n",
    "    print(f\"Average Precision: {average_precision}\")\n",
    "    print(f\"Average Recall: {average_recall}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fisherface(useSym):\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_accuracy = []\n",
    "\n",
    "    misclassified_images = []\n",
    "    misclassified_true_labels = []\n",
    "    misclassified_pred_labels = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            training_label_set_person_i = y_train[i]\n",
    "            training_set_person_i = normalize_list(x_train[i], useSym)\n",
    "\n",
    "            testing_label_set_person_i = y_test[i]\n",
    "            testing_set_person_i = normalize_list(x_test[i], useSym)\n",
    "\n",
    "            train_images_flat = np.array([p.flatten() for p in training_set_person_i])\n",
    "            test_images_flat = np.array([p.flatten() for p in testing_set_person_i])\n",
    "\n",
    "            # Avoid singularity issue in LDA and help generalize\n",
    "            pca = PCA(n_components=min(5, train_images_flat.shape[0] - 1))\n",
    "            train_pca = pca.fit_transform(train_images_flat)\n",
    "            test_pca = pca.transform(test_images_flat)\n",
    "\n",
    "            lda = LDA()\n",
    "            lda.fit(train_pca, training_label_set_person_i)\n",
    "\n",
    "            train_fisherfaces = lda.transform(train_pca)\n",
    "            test_fisherfaces = lda.transform(test_pca)\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=1)\n",
    "            knn.fit(train_fisherfaces, training_label_set_person_i)\n",
    "            test_predictions = knn.predict(test_fisherfaces)\n",
    "\n",
    "            precision, recall, accuracy = calculate_metrics(\n",
    "                testing_label_set_person_i, test_predictions\n",
    "            )\n",
    "\n",
    "            all_precision.append(precision)\n",
    "            all_recall.append(recall)\n",
    "            all_accuracy.append(accuracy)\n",
    "\n",
    "            (\n",
    "                misclassified_batch_images,\n",
    "                misclassified_batch_true_labels,\n",
    "                misclassified_batch_pred_labels,\n",
    "            ) = track_misclassifications(\n",
    "                testing_set_person_i,\n",
    "                testing_label_set_person_i,\n",
    "                test_predictions,\n",
    "            )\n",
    "\n",
    "            misclassified_images.extend(misclassified_batch_images)\n",
    "            misclassified_true_labels.extend(misclassified_batch_true_labels)\n",
    "            misclassified_pred_labels.extend(misclassified_batch_pred_labels)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"An error occurred at index {i} for one of the images: {e} Skipping {y_train[i][0]}'s dataset.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "    return (all_precision, all_recall, all_accuracy), (\n",
    "        misclassified_images,\n",
    "        misclassified_true_labels,\n",
    "        misclassified_pred_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_eigenface(useSym):\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_accuracy = []\n",
    "\n",
    "    misclassified_images = []\n",
    "    misclassified_true_labels = []\n",
    "    misclassified_pred_labels = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            training_label_set_person_i = y_train[i]\n",
    "            training_set_person_i = normalize_list(x_train[i], useSym)\n",
    "            testing_label_set_person_i = y_test[i]\n",
    "            testing_set_person_i = normalize_list(x_test[i], useSym)\n",
    "\n",
    "            train_images_flat = np.array([p.flatten() for p in training_set_person_i])\n",
    "            test_images_flat = np.array([p.flatten() for p in testing_set_person_i])\n",
    "\n",
    "            pca = PCA(n_components=min(5, train_images_flat.shape[0] - 1))\n",
    "            train_pca = pca.fit_transform(train_images_flat)\n",
    "            test_pca = pca.transform(test_images_flat)\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=1)\n",
    "            knn.fit(train_pca, training_label_set_person_i)\n",
    "            test_predictions = knn.predict(test_pca)\n",
    "\n",
    "            precision, recall, accuracy = calculate_metrics(\n",
    "                testing_label_set_person_i, test_predictions\n",
    "            )\n",
    "\n",
    "            all_precision.append(precision)\n",
    "            all_recall.append(recall)\n",
    "            all_accuracy.append(accuracy)\n",
    "\n",
    "            (\n",
    "                misclassified_batch_images,\n",
    "                misclassified_batch_true_labels,\n",
    "                misclassified_batch_pred_labels,\n",
    "            ) = track_misclassifications(\n",
    "                testing_set_person_i, testing_label_set_person_i, test_predictions\n",
    "            )\n",
    "\n",
    "            misclassified_images.extend(misclassified_batch_images)\n",
    "            misclassified_true_labels.extend(misclassified_batch_true_labels)\n",
    "            misclassified_pred_labels.extend(misclassified_batch_pred_labels)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"An error occurred at index {i} for one of the images: {e} Skipping {y_train[i][0]}'s dataset.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "    return (all_precision, all_recall, all_accuracy), (\n",
    "        misclassified_images,\n",
    "        misclassified_true_labels,\n",
    "        misclassified_pred_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fisherface, misclassified_fisherface = eval_fisherface(useSym=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"Using FisherFace\", *metrics_fisherface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_misclassifications(\"Using FisherFace\", *misclassified_fisherface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_sift, misclassified_sift = eval_eigenface(useSym=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"Using EigenFace\", *metrics_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_misclassifications(\"Using EigenFace\", *misclassified_sift)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
