{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as urlreq\n",
    "\n",
    "import scipy.io as scio\n",
    "from face_frontalization import frontalize\n",
    "from face_frontalization import camera_calibration as calib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 8\n",
    "face_image_target_size = (64, 64)\n",
    "\n",
    "base_folder = \"demo/dataset-norm\"\n",
    "haarcascade = \"model_checkpoints/haarcascade.xml\"\n",
    "haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml\"\n",
    "LBFmodel = \"model_checkpoints/lbfmodel.yaml\"\n",
    "LBFmodel_url = \"https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml\"\n",
    "\n",
    "frontalize_model_name = \"model_dlib\"\n",
    "frontalize_model_path = \"model_checkpoints/model3Ddlib.mat\"\n",
    "\n",
    "eye_mask_mat = \"eyemask\"\n",
    "eye_mask_mat_path = \"model_checkpoints/eyemask.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, url in zip([haarcascade, LBFmodel], [haarcascade_url, LBFmodel_url]):\n",
    "    if os.path.exists(filename):\n",
    "        print(\"File exists\")\n",
    "    else:\n",
    "        urlreq.urlretrieve(url, filename)\n",
    "        print(\"File downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for img_name in os.listdir(base_folder):\n",
    "    img_path = os.path.join(base_folder, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier(haarcascade)\n",
    "landmark_detector = cv2.face.createFacemarkLBF()\n",
    "landmark_detector.loadModel(LBFmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_face(img):\n",
    "    model3D = frontalize.ThreeD_Model(frontalize_model_path, frontalize_model_name)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    if len(faces) == 0:\n",
    "        raise RuntimeError(\"No faces detected.\")\n",
    "\n",
    "    main_face = np.array([max(faces, key=lambda rect: rect[2] * rect[3])])\n",
    "    retval, landmarks = landmark_detector.fit(gray, main_face)\n",
    "    if not retval or len(landmarks) == 0:\n",
    "        raise RuntimeError(\"Could not detect landmarks.\")\n",
    "\n",
    "    # OpenCV returns landmarks as a list, where each element is an array of shape (1, 68, 2).\n",
    "    lmarks = landmarks[0][0]\n",
    "    proj_matrix, _, _, _ = calib.estimate_camera(model3D, lmarks)\n",
    "\n",
    "    eyemask = np.asarray(scio.loadmat(eye_mask_mat_path)[eye_mask_mat])\n",
    "    frontal_raw, frontal_sym = frontalize.frontalize(\n",
    "        img, proj_matrix, model3D.ref_U, eyemask\n",
    "    )\n",
    "\n",
    "    return frontal_raw, frontal_sym\n",
    "\n",
    "\n",
    "def obtain_only_face(i, frontal_view):\n",
    "    faces = face_detector.detectMultiScale(\n",
    "        frontal_view, scaleFactor=1.1, minNeighbors=5\n",
    "    )\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        raise RuntimeError(f\"No faces detected (after frontalization) {i}.\")\n",
    "\n",
    "    main_face = np.array([max(faces, key=lambda rect: rect[2] * rect[3])])\n",
    "    _, landmarks = landmark_detector.fit(frontal_view, main_face)\n",
    "\n",
    "    lmarks = landmarks[0][0]\n",
    "    hull = cv2.convexHull(np.array(lmarks, dtype=np.int32))\n",
    "\n",
    "    min_x = min(lmarks, key=lambda p: p[0])[0]\n",
    "    max_x = max(lmarks, key=lambda p: p[0])[0]\n",
    "    min_y = min(lmarks, key=lambda p: p[1])[1]\n",
    "    max_y = max(lmarks, key=lambda p: p[1])[1]\n",
    "\n",
    "    mask = np.zeros((frontal_view.shape[0], frontal_view.shape[1]), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [hull], 255)\n",
    "\n",
    "    masked_face = frontal_view.copy()\n",
    "    if masked_face.dtype != np.uint8:\n",
    "        masked_face = np.uint8(np.clip(masked_face, 0, 255))\n",
    "\n",
    "    masked_face[mask == 0] = 0\n",
    "    masked_face = masked_face[\n",
    "        int(min_y) - 5 : int(max_y) + 5, int(min_x) - 5 : int(max_x) + 5\n",
    "    ]\n",
    "\n",
    "    masked_face = cv2.cvtColor(masked_face, cv2.COLOR_BGR2GRAY)\n",
    "    resized_face = cv2.resize(masked_face, face_image_target_size)\n",
    "    return resized_face\n",
    "\n",
    "\n",
    "def normalize_list(image_list, useSym):\n",
    "    frontalized_input = [normalize_face(x)[1 if useSym else 0] for x in image_list]\n",
    "\n",
    "    cropped_input = [obtain_only_face(i, x) for i, x in enumerate(image_list)]\n",
    "    frontalized_cropped_input = [\n",
    "        obtain_only_face(i, x) for i, x in enumerate(frontalized_input)\n",
    "    ]\n",
    "\n",
    "    return cropped_input, frontalized_cropped_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_input, frontalized_cropped_input = normalize_list(images, useSym=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(images)\n",
    "fig, axes = plt.subplots(num_images, 3, figsize=(6, 2 * num_images))\n",
    "for i in range(num_images):\n",
    "    axes[i, 0].imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    if i == 0:\n",
    "        axes[i, 0].set_title(f\"Original\")\n",
    "\n",
    "    axes[i, 1].imshow(cv2.cvtColor(cropped_input[i], cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 1].axis(\"off\")\n",
    "    if i == 0:\n",
    "        axes[i, 1].set_title(f\"Cropped\")\n",
    "\n",
    "    axes[i, 2].imshow(cv2.cvtColor(frontalized_cropped_input[i], cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 2].axis(\"off\")\n",
    "    if i == 0:\n",
    "        axes[i, 2].set_title(f\"Front\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
